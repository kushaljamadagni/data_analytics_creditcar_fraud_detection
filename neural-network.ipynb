{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import tensorflow as tf\n",
    "\n",
    "#import pandas_ml as pdml\n",
    "from sklearn.metrics import jaccard_score\n",
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv', low_memory=False)\n",
    "X = df.iloc[:,:-1]\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 492 fraud data points and 284315 regular data points.\n"
     ]
    }
   ],
   "source": [
    "frauds = df.loc[df['Class'] == 1]\n",
    "non_frauds = df.loc[df['Class'] == 0]\n",
    "print(\"We have\", len(frauds), \"fraud data points and\", len(non_frauds), \"regular data points.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set:  (190820, 30)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of training set: \", X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplest Neural Network (for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 961\n",
      "Trainable params: 961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=30, activation='relu'))     # kernel_initializer='normal'\n",
    "model.add(Dense(1, activation='sigmoid'))                 # kernel_initializer='normal'\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5964/5964 [==============================] - 6s 962us/step - loss: 8.8075 - accuracy: 0.9963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa07ccd2cd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train.values, y_train, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  [0.8562776446342468, 0.9978720545768738]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss: \", model.evaluate(X_test.values, y_test, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_test.values).T[0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgymh/anaconda/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:259: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.TN) / self.NegativeTest)\n",
      "/Users/georgymh/anaconda/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:304: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (self.TN + self.FP) * (self.TN + self.FN)))\n",
      "/Users/georgymh/anaconda/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:339: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.FNR) / self.TNR)\n",
      "/Users/georgymh/anaconda/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:251: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.FN) / self.NegativeTest)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "Predicted      0  1  __all__\n",
      "Actual                      \n",
      "0          93834  0    93834\n",
      "1            153  0      153\n",
      "__all__    93987  0    93987\n",
      "\n",
      "\n",
      "Overall Statistics:\n",
      "\n",
      "Accuracy: 0.998372115293\n",
      "95% CI: (0.99809303053729637, 0.99861967548897745)\n",
      "No Information Rate: ToDo\n",
      "P-Value [Acc > NIR]: 1.0\n",
      "Kappa: 0.0\n",
      "Mcnemar's Test P-Value: ToDo\n",
      "\n",
      "\n",
      "Class Statistics:\n",
      "\n",
      "Classes                                         0           1\n",
      "Population                                  93987       93987\n",
      "P: Condition positive                       93834         153\n",
      "N: Condition negative                         153       93834\n",
      "Test outcome positive                       93987           0\n",
      "Test outcome negative                           0       93987\n",
      "TP: True Positive                           93834           0\n",
      "TN: True Negative                               0       93834\n",
      "FP: False Positive                            153           0\n",
      "FN: False Negative                              0         153\n",
      "TPR: (Sensitivity, hit rate, recall)            1           0\n",
      "TNR=SPC: (Specificity)                          0           1\n",
      "PPV: Pos Pred Value (Precision)          0.998372         NaN\n",
      "NPV: Neg Pred Value                           NaN    0.998372\n",
      "FPR: False-out                                  1           0\n",
      "FDR: False Discovery Rate              0.00162788         NaN\n",
      "FNR: Miss Rate                                  0           1\n",
      "ACC: Accuracy                            0.998372    0.998372\n",
      "F1 score                                 0.999185           0\n",
      "MCC: Matthews correlation coefficient         NaN         NaN\n",
      "Informedness                                    0           0\n",
      "Markedness                                    NaN         NaN\n",
      "Prevalence                               0.998372  0.00162788\n",
      "LR+: Positive likelihood ratio                  1         NaN\n",
      "LR-: Negative likelihood ratio                NaN           1\n",
      "DOR: Diagnostic odds ratio                    NaN         NaN\n",
      "FOR: False omission rate                      NaN  0.00162788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgymh/anaconda/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:236: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.TP) / self.PositiveTest)\n",
      "/Users/georgymh/anaconda/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:267: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.FP) / self.PositiveTest)\n",
      "/Users/georgymh/anaconda/lib/python3.6/site-packages/pandas_ml/confusion_matrix/bcm.py:332: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return(np.float64(self.TPR) / self.FPR)\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural Network after Oversampling, Scaling, and PCA (10 components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.4448525 , -0.82152584, -0.17220272, ..., -1.68354709,\n",
       "        -0.36831529, -0.26526041],\n",
       "       [-2.18904068, -0.72670741,  0.87786002, ..., -1.11916378,\n",
       "         0.88673604,  0.15649273],\n",
       "       [-2.56965118, -0.32978225,  0.50729605, ...,  0.28042025,\n",
       "        -0.52953134, -0.89572361],\n",
       "       ..., \n",
       "       [ 2.69419572,  0.48653567,  0.2388476 , ..., -0.12258431,\n",
       "        -0.03518196,  2.11292303],\n",
       "       [ 1.87017491,  0.51751185, -0.65521505, ..., -0.29825332,\n",
       "         0.56147921, -0.83751973],\n",
       "       [-1.68516108,  0.32780463, -2.36850653, ..., -1.48417405,\n",
       "        -2.18489752, -1.24560614]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "df2 = pdml.ModelFrame(X_train, target=y_train)\n",
    "sampler = df2.imbalance.over_sampling.SMOTE()\n",
    "oversampled = df2.fit_sample(sampler)\n",
    "X2, y2 = oversampled.iloc[:,:-1], oversampled['Class']\n",
    "\n",
    "data = scale(X2)\n",
    "pca = PCA(n_components=10)\n",
    "X2 = pca.fit_transform(data)\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 27)                297       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 20)                560       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 1,298\n",
      "Trainable params: 1,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(10, input_dim=10, activation='relu')) \n",
    "model2.add(Dense(27, activation='relu'))\n",
    "model2.add(Dense(20, activation='relu'))\n",
    "model2.add(Dense(15, activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380962 samples, validate on 93987 samples\n",
      "Epoch 1/5\n",
      "380962/380962 [==============================] - 39s - loss: 0.0159 - acc: 0.9948 - val_loss: 8.4765 - val_acc: 0.4683\n",
      "Epoch 2/5\n",
      "380962/380962 [==============================] - 37s - loss: 0.0056 - acc: 0.9984 - val_loss: 8.4765 - val_acc: 0.4683\n",
      "Epoch 3/5\n",
      "380962/380962 [==============================] - 39s - loss: 0.0047 - acc: 0.9987 - val_loss: 8.4765 - val_acc: 0.4683\n",
      "Epoch 4/5\n",
      "380962/380962 [==============================] - 39s - loss: 0.0041 - acc: 0.9989 - val_loss: 8.4765 - val_acc: 0.4683\n",
      "Epoch 5/5\n",
      "380962/380962 [==============================] - 37s - loss: 0.0038 - acc: 0.9990 - val_loss: 8.4765 - val_acc: 0.4683\n"
     ]
    }
   ],
   "source": [
    "X2_test = pca.fit_transform(X_test)\n",
    "h = model2.fit(X2, y2, epochs=5, validation_data=(X2_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  [8.4765311850906038, 0.46830944705150501]\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss: \", model2.evaluate(X2_test, y_test, verbose=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_predicted = np.round(model2.predict(X2_test)).T[0]\n",
    "y2_correct = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "Predicted    0.0    1.0  __all__\n",
      "Actual                          \n",
      "0.0        43924  49910    93834\n",
      "1.0           62     91      153\n",
      "__all__    43986  50001    93987\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAHVCAYAAACkOBIuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfesAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120c61710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population: 93987\n",
      "P: 153\n",
      "N: 93834\n",
      "PositiveTest: 50001\n",
      "NegativeTest: 43986\n",
      "TP: 91\n",
      "TN: 43924\n",
      "FP: 49910\n",
      "FN: 62\n",
      "TPR: 0.59477124183\n",
      "TNR: 0.468103246158\n",
      "PPV: 0.00181996360073\n",
      "NPV: 0.998590460601\n",
      "FPR: 0.531896753842\n",
      "FDR: 0.998180036399\n",
      "FNR: 0.40522875817\n",
      "ACC: 0.468309447051\n",
      "F1_score: 0.00362882322447\n",
      "MCC: 0.00507988302502\n",
      "informedness: 0.0628744879882\n",
      "markedness: 0.000410424201828\n",
      "prevalence: 0.00162788470746\n",
      "LRP: 1.11820806864\n",
      "LRN: 0.865682435437\n",
      "DOR: 1.2917070081\n",
      "FOR: 0.0014095393989\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix2 = ConfusionMatrix(y2_correct, y2_predicted)\n",
    "print(\"Confusion matrix:\\n%s\" % confusion_matrix2)\n",
    "confusion_matrix2.plot(normalized=True)\n",
    "plt.show()\n",
    "confusion_matrix2.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
